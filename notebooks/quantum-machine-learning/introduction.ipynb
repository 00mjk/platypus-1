{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Machine learning has established itself as a successful interdisciplinary field which seeks to find patterns in data. Throwing in quantum computing gives rise to interesting areas of research that aim to use the principles of quantum mechanics to augment machine learning or vice-versa. In this chapter, we aim to give you a glimpse into the exciting and rapidly changing field of near-term quantum machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning (ML)\n",
    "\n",
    "Before we dive into quantum machine learning, let's do a whirlwind overview of  machine learning. For our purposes, machine learning can be split roughly into three subfields: supervised learning, unsupervised learning and reinforcement learning. \n",
    "\n",
    "- *Supervised Learning*: given tuples of labeled data $(x_i,y_i)$, we aim to learn the function that maps $f: x \\mapsto y$ and generalizes to unseen inputs; for example, given a set of labeled photos of cats or dogs, being able to identify new photos of cats or dogs.  \n",
    "\n",
    "\n",
    "- *Unsupervised Learning*: given a collection of unlabeled data $(x_i)$, we aim to learn some structure of the data; for example, grouping a set of viewers based their movie viewing history in order to recommend new movies.\n",
    "\n",
    "\n",
    "- *Reinforcement Learning*: given access to an environment that rewards us based on our actions, we aim to maximise our expected rewards; for example, algorithmically learning how to play PAC-MAN."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Machine Learning (QML)\n",
    "\n",
    "There are four different approaches for combining quantum computing and machine learning, which are differentiated by whether the data is classical _(**C**)_ or quantum _(**Q**)_ in nature, or whether the algorithm is executed on a classical _(**C**)_ or quantum _(**Q**)_ computer, as illustrated below from Reference [1](#references). In this context, a quantum dataset consists of observations from a natural or artificial quantum system, such as measurements of qubit dynamics, while a classical dataset consists of observations from a classical system, such as times series, text, or images.\n",
    "\n",
    "<div><img src=\"images/qml_approaches.png\" width=\"250\"></div> \n",
    "\n",
    "- **CC**: refers to processing _**C**lassical_ data using _**C**lassical_ computers, but using algorithms inspired by quantum computing, such as this [recommendation system](https://doi.org/10.1145/3313276.3316310) algorithm.\n",
    "- **CQ**: refers to processing _**Q**uantum_ data using _**C**lassical_ machine learning algorithms. This is an active area of investigation, with classical machine learning algorithms used in many areas in the quantum computing, such as qubit [characterization](https://doi.org/10.1038/s41524-020-0282-0), [control](https://doi.org/10.1038/s41534-019-0141-3) and [readout](https://link.aps.org/doi/10.1103/PhysRevLett.114.200501).\n",
    "- **QQ**: refers to processing _**Q**uantum_ data using _**Q**uantum_ machine learning algorithms. This is an interesting topic, but very much still in its infancy.\n",
    "- **QC**: refers to processing _**C**lassical_ data using _**Q**uantum_ machine learning algorithms, and will be what this chapter focuses on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two distinct categories of **QC** algorithms: those that require quantum random access memory (qRAM), where data can be accessed in superposition, and those that don't. The various proposed qRAM-based QML algorithms, eg. [qPCA](https://doi.org/10.1038/nphys3029), [qSVM](https://doi.org/10.1103/PhysRevLett.113.130503) and [qClustering](https://arxiv.org/abs/1307.0411), boast exponental speedups compared to their classical algorithms, however there are currently no viable hardware candidates for realizing qRAM. \n",
    "\n",
    "Recently, most of the focus of **QC** approaches to machine learning have been on heuristic near-term algorithms that can be executed on the current quantum devices. Classical machine learning techniques have made great strides in the past decade, enabled in large part by the availability of sufficiently powerful hardware. Perhaps the existence of quantum hardware will further enable advances in the field?\n",
    "\n",
    "Note that this is a very dynamic area of current investigation by multiple research teams worldwide, and there are still many open questions, as well as confusing terminology and notation. We will try and be as consistent as possible in this chapter, but also point out when concepts have been referred to by different names, or how different concepts relate to each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Variational Quantum Classifier\n",
    "\n",
    "Here is an example of a heuristic supervised near-term quantum machine learning algorithm, which given a set of datapoints ($\\vec{x_i}$) and associated labels ($y_i$), it builds a model that predicts labels of new datapoints. You will learn later that it is the [variational quantum classifier](vqc.ipynb).\n",
    "\n",
    "<div><img src=\"images/vqc.png\" width=\"600\"></div> \n",
    "\n",
    "Similar to the [variational quantum eigensolver](https://qiskit.org/textbook/ch-applications/vqe-molecules.html), in this algorithm, a classical computer works with a quantum computer. As with all supervised machine learning algorithms, there are separate training and testing phases.\n",
    "\n",
    "For both the training and the testing stages, the quantum circuit that implements the algorithm has three main parts:  the data encoding circuit, the variational circuit and the measurement.\n",
    "\n",
    "- The data encoding circuit ($\\mathcal{U}_\\Phi$) transforms the register from the starting state (usually $|000\\dots 0\\rangle$) into a state representing the input data. This circuit obviously depends on the input data, $\\vec{x_i}$, so we say that $\\mathcal{U}_\\Phi$ is _parametrized_ by $\\vec{x_i}$.\n",
    "- The variational circuit ($\\mathcal{W}$) transforms the output of $\\mathcal{U}_\\Phi$ into something that helps us predict the labels corresponding to $\\vec{x_i}$. We tweak this circuit according to a set of variables, $\\vec{\\theta}$, i.e. $\\mathcal{W}$ is parametrized by $\\vec{\\theta}$.\n",
    "\n",
    "In the training phase, we are trying to find the values for $\\vec{\\theta}$ that give us the best predictions. The classical computer compares the predicted labels, $\\hat{y_i}$, to the provided labels, $y_i$, and we calculate the success of our predictions using a cost function. Based on this cost, the classical computer chooses another value for $\\vec{\\theta}$ using a classical optimization algorithm. This new $\\vec{\\theta}$ is then used to run a new circuit, and the process is repeated until the cost function stabilizes.\n",
    "\n",
    "Depending on the choice of data encoding and variational circuits, this algorithm can be executed on the current noisy hardware, however, since it is a heuristic algorithm, there isn't a definitive provable advantage over classical algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a id=\"references\"></a>\n",
    "\n",
    "1.  Maria Schuld and Francesco Petruccione, *Supervised Learning with Quantum Computers*, Springer 2018, [doi:10.1007/978-3-319-96424-9](https://www.springer.com/gp/book/9783319964232).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
